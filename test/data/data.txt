Generative model for inverse design and forward prediction of disorder waveguide in linear and nonlinear regimes

1School of Physics and Astronomy, University of St. Andrews, Fife, KY16 9SS, United Kingdom 
2School of Computer Science, University of St. Andrews, Fife, KY16 9SS, United Kingdom
Abstract: 
Complex designing with strong nonlinear effects of optical devices is attracting researchers nowadays. Using conventional libraries to search complex design spaces is extremely time consuming. The data-driven machine learning framework is nowadays the state-of-art technique opening up various parameters degrees of freedom in complex system design. In this work, we use generative adversarial network (GAN) and convolutional neural networks (CNNs) to inverse design and forward prediction of random waveguides in linear and nonlinear regimes. Full advantage of machine learning was taken to explore the linear and nonlinear effect of random waveguide with respect of transmission spectra in telecommunication wavelength. 
Codes is available here: https://github.com/ZooBeasts/WGAN-GP_Inverse_Design_disorder_Waveguide_nanophotonics 
Introduction 
Current nanophotonic devices heavily rely on complex nanostructures to achieve sophisticated functionalities. As the complexity of these systems increases, designing them becomes more challenging. Conventional design approaches, such as Finite different time domain (FDTD), or Beam propagation method (BPM) with particle swarm optimization, genetic algorithms, etc., [1,2] that finding a suitable design often requires hundreds or even thousands of simulations and extremely time consuming. Therefore, the data-driven machine learning framework to facilitate complex design in modern nanophotonics is needed. This opens up possibilities for solving complex system problems, for instance, inverse design and forward prediction of optical responses in the nonlinear regime. By integrating data-driven techniques with nanophotonics, it is possible to enhance the design process and enable more efficient exploration of design spaces [3]. This approach holds promise for achieving improved performance and functionality in nanophotonic devices. With the integration of these novel methods, we can overcome the limitations of conventional design approaches and revolutionize the field of nanophotonics.

In the field of integrated photonics, significant progress has been made in utilizing machine learning techniques for nanophotonics design [4] . The utilization of advanced methodologies, including Variational Autoencoders (VAEs) [5,6] and Generative Adversarial Networks (GANs) [7,8], has been pivotal in addressing intricate design challenges, particularly in the context of metasurfaces and metamaterials aimed at optimizing absorption and transmission characteristics, among other factors. VAEs have exhibited notable effectiveness in modeling the distribution of well-structured nanopatterned power splitters, accommodating varying splitting ratios for waveguide designs, while GANs have demonstrated successful application in the inverse design of metamaterials and waveguides.

Simultaneously, there has been a concerted effort to explore the predictive capabilities of these neural network (NN) approaches in predicting nanopatterns for optical responses. Previous studies have demonstrated the effectiveness of artificial intelligence integrated optimization processes using neural networks (NN) to accelerate optimization [9]. Notably, deep neural network (DNN) models have been deployed both for forward prediction and inverse design, facilitating the establishment of correlations between desired performance metrics such as transmission and reflection spectra [10]. Consequently, the pursuit of well-structured waveguide designs has emerged as a prominent focus in recent investigations that employ deep neural networks (DNNs) [11,12].

However, as the complexity of waveguides required by the industry continues to increase, the nonlinearity of optical waveguides poses a significant challenge for researchers. This challenge arises from the intricate nonlinear behavior, which lacks general or trivial solutions. In contrast of linearity, random waveguide designs have emerged as a promising avenue for enhancing nonlinearity in integrated chips and laser design. Nevertheless, the inherent disorder in these waveguide structures complicates the identification of specific design parameters and optimization criteria. Consequently, formulating an objective function or optimization framework for inverse design becomes a challenging task. Furthermore, random waveguides often offer multiple solutions capable of achieving similar or desired functionalities. This multiplicity of solutions further amplifies the complexity associated with the inverse design process. Additionally, the diverse degrees of freedom associated with various parameters result in sparse data types. Therefore, encoding and classifying input features become crucial challenges. The complexity of nonlinear behaviors in waveguides has been underexplored, primarily due to the specific functionality requirements in different waveguide designs. Machine learning offers the potential to gain insights into nonlinear behaviors in certain general cases, such as disorder waveguides. For instance, Lauri Salmela et al. successfully employed a Long Short-Term Memory network (LSTM) to predict nonlinear behaviors in wavelength based on given intensity spectra and time intervals[13]. [14] transmission matrix etc Nevertheless, comprehending nonlinear behaviors remains a formidable challenge in the field of nanophotonics. (waiting for double check for paper)

In our study, we propose employing a conditional Generative Adversarial Network (GAN) with Wasserstein distance and gradient penalty as the network's loss function [15]. This approach is used to explore the design possibilities of random waveguides within the linear regime. It is important to note that our dataset exhibits an extreme sparsity feature, a characteristic intrinsic to the data structure itself. Traditional GANs faced a significant challenge in dealing with mode collapse, primarily because the data structure lacks informative features. Our objective is to leverage the Wasserstein distance metric to maximize the incorporation of randomness features in order to reconstruct the geometry based on available information. Furthermore, we utilize groups of convolutional neural networks to predict the nonlinear behavior of random waveguides in terms of transmission spectra, within acceptable errors. These predictions inputs are derived from either Finite-Difference Time-Domain (FDTD) simulations or generated inverse structures. This multifaceted approach enables us to explore and harness the potential of random waveguides within the linear regime, with the aim of advancing our understanding and capabilities in this intricate field.

Simulation setting and Dataset
In this work, we simplified the modelling of random waveguide and characterized problem by ‘in-out’ transmission mode. We use the self-written Fortran FDTD simulator [16] . In our FDTD, we set a vectorial computation of nonlinear Maxwell equation for dispersive materials. And the way to describe the materials is polarization P formed by nonlinear Lorentz oscillator along with Yee’s grid and uniaxial phase-matched layers, see Eq.(1). 
∂_t^2 P+2γ_0 ∂_t P+ ω_0^2 f(P)P= ε_0 (ε_s-1) ω_0^2 E                         (1)
Function of Lorentz oscillatorf(P) was specific stated. f(P)=1 is a linear single-pole dispersive medium. f(P)=[1+(P/P_0 )^2 ]^(-3/2) is an isotropic material. P_0= √((9/2)(((ε_s-1)^3 ε_0^(3/2) μ_0^(1/2))/(ε_s n_2 )), where n_2is Kerr nonlinearity coefficient n_2=1.5×10^(-17)  m^2 W^(-1), ω_0=1.1 × 10^16, γ_0=2 ×10^5 (MKS units), n_2=1.5×10^(-17)  m^2 W^(-1), and temporal steps dt=0.02fs. Non-instantaneous four-wave mixing and higher order nonlinearities can be described by Equ.1 

To design the disorder waveguide, we choose a simple 1 x 1 waveguide with input and output port width 5.6 μm and center design space is 5.6 x 5.6 μm² square as template on a standard fully etched SOI platform.  The number of etched holes we interested in is 200. Locations of etched holes are randomly distributed without and pre-defined patterns, and structures are generated by MATLAB 2021a. We simulated template structures via FDTD solver that mentioned above, where results were validated by experiments. Generated transmission spectra were labels with corresponding geometries. Each etched holes are 1 nm pixel and be binary state of 1 with respect for refractive index of air n= n_air, and 0 for not etched place in design space n= n_silicon.  When feed the convolutional neural network (CNN), the input space size is up sampling to 64 x 64 size array. 

In order to train, we generated a dataset comprising 100,000 randomly etched hole vectors for the 1mW input power, each paired with its corresponding transmission response as a label. The process was then repeated four more times for input powers of 1W, 10W, 50W, and 100W for advance use, resulting in a total of 500,000 transmission response data points, all corresponding to the same 100,000 geometries.
  Fig. 1: Overview of the GAN inverse design process and CNN forward prediction. Starting with TE mode of template SOI waveguide and schematic of nanostructured waveguide with a footprint of 5.6 x 5.6 μm², Square blocks indicate location of etch holes. Followed by GAN inverse design that takes transmission responses and latent vector as input to generate new geometries comparing with real design. Then, CNN forward prediction that takes device geometries as input, corresponding linear and nonlinear transmission responses as outputs. Data validation and evaluation is taken inside the modelling. 

We employed a conditional Generative Adversarial Network (GAN) architecture to solve the inverse design problem. The GAN consists of two parts: the generator (G) and the discriminator (D). The generator takes a latent vector (z) and transmission spectra (y) as input and generates a new geometry G(z, y) that satisfies the given input conditions. On the other hand, the discriminator's role is to distinguish between the generated geometry and the real geometry (x) based on the input conditions (y), as illustrated in Fig 1. However, disorder geometry formation is sparse data type. When train the network, etched holes location information will ‘loss’ due to multiple geometries leads to multiple high degree of resemblance. Yet, problem remains that it cannot be categorized them as different type. Therefore, in initial training process, GAN often trapped in local minimum and cause discriminator overtake generator and leads to mode collapse (generator only generate identical geometry despite input). Regular GAN loss is showing Eq.2
〖min〗_G 〖max〗_D V(D,G)= E_(x~P_data(x)  ) [logD(x)]+E_(z~P_z (z) ) (log⁡(1-D(G(z))   (2)
D(G(z)) is the probability that the output of the generator G is a real image. To address the issue of mode collapse that arises when using regular conditional GANs with numerous sparse type feature inputs, we adopted the Wasserstein distance with gradient penalty [15] as our loss function, Eq.3. 
〖min〗_G 〖max〗_D  E[c(x)]+E(log⁡(c(g(z))+λE(||∇c(x ̂ )| |_2-1)^2             (3)
The first half is the Wasserstein loss that estimates the data distance. The second half is gradient penalty as regularization terms and ensuring loss function is continuous and differentiable. 

This allows us to maximize the distribution overlap between the generated geometry information and the real geometry information. This strategic approach not only mitigated the randomization issues typically encountered in random waveguide design but also leveraged the power of the CNN-based GAN architecture. By doing so, we can mitigate the problem of the discriminator(in WGAN, Discriminator renames as Critic) being easily fooled by the generator and improve the generation of accurate geometries. During the data processing phase, we intentionally refrained from providing explicit labels to the critic for identifying true or false samples. Instead, we designed the critic to classify the maximum distribution distance. This approach enhances the GAN's ability to effectively learn the underlying data distribution and improves the overall performance of the conditional GAN for inverse design applications.

The objective for inverse design is to fully leverage the disorder degree of freedom and explore the entire parameter space effectively. To achieve this, randomizing the discriminator weights and bias during the training process has been implemented to enhance training. We have selected the input data consisting of transmission spectra and corresponding geometries for the 1mW input power. To ensure a comprehensive representation of the spectra, we have interpolated 50 points between 1500 to 1550 nm to obtain 200 points for input. For the generator, we initialize the latent vector with 50 random numbers uniformly distributed between 0 and 1 and conditionally concatenate 200 points spectra data, allowing the GAN to explore diverse solutions. To ensure reproducibility of the results, we have set the fixed seed for the network. Both the generator and critic loss functions are optimized using the Adam optimization algorithm with the same learning rate. Detailed network structures are illustrated in fig.2. Specific hyperparameter values can be found in Table 1
 
Fig 2: (a) shows the forward network structure, 5 layers with 3 convolution layers of kernel size 4, stride 1, flatten into fully connected network with 256 neurons and last layer with 50 neurons, and output is 50 points of spectra. The output of each layer is passed through a ReLU activation function before being passed on to the next layer. Two max pooling layers was implemented in between. (b) Detailed network structure of the Critic. Critic consists of 5 convolution layers, the output of each layer is Instance-normalized and passed through LeakyRelu activation function before being passed through next layer. The last layer is flattened into a 1D array and the reduced sum is calculated to represent its Wasserstein distance. The Critic takes real geometry along with corresponding transmission spectra and fake geometry as input. (c) Detailed network structure of the generator. It consists of 5 layers transposed convolution layers. In the end the tensor is flatten into 2D image The output of each layer is batch-normalized and passed through a LeakyReLU activation function. After the last transposed convolutional layer, a tanh activation function generates a 2D image representing new random design. Details of each output tensor, shapes of the (transposed) convolutional kernels and strides used during convolutions are given in the figure. 

Table 1. Hyperparameters settings
 	Forward Prediction	Inverse Design (G)	Inverse Design (D)
Training set	450,000	90,000	90,000
Test set	50,000	10,000	10,000
Batch size	85	64	64
Learning rate	1e-3	1e-4	1e-4
Epochs 	100	400	400
Seed	Random	999	999
Activation function	Relu + linear(last layer)	Relu + Tanh(last layer)	LeakyRelu
Loss function	MSE	Wasserstein distance + GP	Wasserstein distance + GP

We employ a Convolutional Neural Network for the forward problem to predict the 50 spectral data elements within the transmission range of 1500 to 1550 nm, using a linear reference input power of 1mW, where input consists of a 64 x 64 design array representing 200 holes as binary images.  The main objective of the CNN is to provide accurate predictions maximum within 20% error accepted for this reference input power, thereby establishing a foundation for extending the modelling approach to incorporate different input power levels.  

This forward problem can be framed as a regression task and serves as a rapid Finite-Difference Time-Domain (FDTD) solver. To optimize the CNN, we utilized the mean square error as the loss function and employed the Adam optimization algorithm [16]. To ensure model generalization and prevent overfitting, we implemented the Early-Stop technique during the training process, which ensures convergence while avoiding excessive fitting to the training data. In process of model evaluation, we split the dataset into training and testing sets, with a ratio of 9:1. Specifically, 90,000 geometries were used for training, along with their corresponding transmission spectra (450,000 data), and 10,000 geometries were reserved for testing, accompanied by their respective transmission spectra (50,000 data). This approach enables efficient and accurate prediction of transmission responses for various input powers, utilizing the shared 100,000 geometries across the different power levels. And we found that increase the convolutional layers do not increase the accuracy but decrease. 

Results and Discussions 
In the evaluation of our inverse design and forward predictions network, we initiated the process by FDTD the template geometry to check how transmission spectra changes when power increase from 1mW to 100W, shows in Fig. 3 (a). For forward prediction CNN network, due to CNN applied early stop method, there is no overfitting observed during the training process. For inverse design GAN network, network loss is converging when critic loss approaching zero, shows in Fig.3 (c).  For quantifying the precision of our prediction framework, we employed the MSE metric, which aligns true numerically verified optical responses with CNN predictions. While the correlation coefficient of CNN predictions was not factored in due to its potential inconsistency with the R2 score of inverse design, which could exhibit close proximity to 100%, the regenerated values were notably misaligned fig.4(b). The observed MSE values for each CNN prediction and GAN loss are presented in fig. 3.
 
Fig 3: Colormap of transmission and power relation, CNN loss, and GAN loss. (a) colormap of example template design from training dataset. It is obverse that while the power increase the transmission values drop. (b) Detailed forward prediction training and test loss. (c) Detailed inverse design generator and critic loss. Only Critic (discriminator) loss is guide for checking the network performance, network converge at where the value is close to 0. 

We directed our efforts toward testing the reliability of the GAN network exclusively with linear reference power (1mW) input. Employing generated geometries, we initially evaluated their performance against FDTD simulations. Meanwhile, these geometries were also processed through the pre-trained CNN prediction group, yielding predictions for both reference and elevated power transmission spectra, enabling a comprehensive comparison. We tested elevated power transmission result as input for GAN to test the generalizability. It seems that it is possible to generated new geometry even for different data distribution. Yet, the FDTD spectra values of generated elevated power geometries were either higher or lower, where interesting thing to see that some generated geometries maintain high R2 scores. Therefore, it leads us to possible address three distinct inverse design challenges: enhancing total transmission within specific wavelength ranges, replicating geometries yielding equivalent responses, and predicting new geometries based on unobserved spectra under linear power conditions Fig.4. Of course, there are existing the low value FDTD geometries results, it still useful for further analysis for different applications, for instance, Mach-Zehnder interconnect. 
Fig 4: Three main inverse design problems. (a) From training dataset, we pick one of the trained images and its FDTD result, then put FDTD result to generating new structures that preform the same behavior. Often it has be seen in metasurface or metamaterial inverse design. (b) for given seen/trained structure and its results, GAN can generate new structure that improve/enhance the total transmission in certain wavelength. (c) For unseen 1mW transmission spectra from test set that GAN can generate correct corresponding structure that preforms same behavior.

In the evaluation of the forward prediction network, we trained distinct CNN forward prediction models, labeled as CNN1mW, CNN1W, CNN10W, CNN50W, and CNN100W, utilizing a comprehensive dataset of 450,000 training instances. Corresponding testing datasets of 10,000 instances were established for each power level. In the subsequent analysis, we present the outcomes from the forward prediction network, followed by the inverse design of random geometries based on provided spectra, as depicted in Fig. 5. Initially, our focus was on assessing the accuracy and discrepancies of the network's forward computations, comparing them with FDTD simulation outcomes. 
 
Fig 5: details of each power real values vs predicted values. (a) Randomly picked geometry from test set. (b),(c),(d),(e),(f) for 1mW, 1W, 10W, 50W, 100W real FDTD and theirs prediction, respectively.

It is notable that the network succeeded in predicting transmission spectra within 20% error range, due to the inherent weak capacity of regular CNN kernels to scan and analyse low-feature images. In our case, we use CNN group as quick validation method to fast approximating of the linear optical response, as well as predicting the higher power nonlinear response in a quick way. Although the accuracy of the CNN groups is in our acceptable range, it is possible to improve the accuracy of prediction by adding more data to force network to remember the hidden relations. 

Here is the example of full processes via FDTD, GAN and CNN. We randomly pick one geometry and transmission response from test set. GAN firstly generates the new geometry shown in fig. 6 (b) and FDTD result is proportional to the original response. Meanwhile, we check the CNN prediction performance for 1W, 10W,50W, 100W power level. acceptation for overall value predictions.
 
Fig. 6: Prediction and performance check for unseen optical response inverse design and forward nonlinear predictions. (a) The transmission spectra and related geometry. (b) The generated new geometry and its FDTD transmission spectra, comparing with the result in (a)   (c). 1W transmission spectra comparison with unseen test 1W FDTD result. (d) 10W transmission spectra comparison with unseen test 10W FDTD result. (e) 50W transmission spectra comparison with unseen test 50W FDTD result. (f) 100W transmission spectra comparison with unseen test 100W FDTD result.


Conclusions 
Our work demonstrates the practical applications of CNN groups in predicting the linear and nonlinear optical responses of nanostructured random waveguides in terms of transmission. Our research also explores the potential of GANs in designing random waveguides, particularly in scenarios with sparse features and a limited number of etched holes. This approach offers a rapid solution for inverse design using neural network methods, creating a novel framework for complex waveguide design. The effectiveness of GANs in addressing geometry inverse design and improving optical responses holds great promise for their widespread integration into the field of nanostructured photonics systems.
In our framework, which includes 200 etched holes within a total design space of 4096, we demonstrate the feasibility of generating randomized geometries based on optical responses for inverse design settings. To mitigate mode collapse issues, we utilize the Wasserstein distance to maximize the calculated distance, incorporating a gradient penalty to prevent gradient exploration. However, it's important to note that this approach extends the total degree of freedom, allowing us to fully leverage the outputs of the GAN as following statement: 
For GAN Predicted Output function O: ∃O(n)
P(O(n))>P(O(real data))   
or P(O(n))<P(O(real data)) 
or P(O(n)∝P(O(real data)
We investigate the probability distribution of values within the dataset denoted as O(n) in comparison to that of O(real data). We observe three distinct scenarios: the probability of values in O(n) being greater than those in O(real data), the probability being lower, or both datasets exhibiting proportional values. These observations help us assess how new geometric designs impact optical response. We highlight the advantages of using GAN outputs for complex photonics engineering, offering a foundation that promises to open up new pathways for intricate waveguide designs. 

Our work exhibit the probability of large space disorder waveguide inverse design and forward prediction. For this complex design problem, further improvement can be address as following: firstly increase the total number of etched holes. Secondly, decrease the total design space. Thirdly, add another discriminator to form a Siamese networks [17], which will increase total training time but improve the accuracy for large design space. Meanwhile, physics informed neural network [18] is also a good framework for trying. 

Acknowledgments
The first author gratefully acknowledges funding from Chinese scholarship council (grant no. 202108060233), The second author gratefully acknowledge funding from Chinese scholarship council (grant no. 202208060113)
Data Availability
The data that support the plots within this paper and other ﬁndings of this study are available from the corresponding authors upon reasonable request.
References
[1]: Robert Scarmozzino, Evan Heller, and Johnny Z. Huang. Assessing the suitability of the BPM and FDTD methods for optical waveguiding problems in photonics. Optica Publishing Group 2000, paper IWB4.
[2]: Chi Man Woo, Huanhao Li, Qi Zhao, and Puxiang Lai. Dynamic mutation enhanced particle swarm optimization for optical wavefront shaping. Optics Express Vol. 29, Issue 12, pp. 18420-18426 (2021).
[3]: Iqbal H. Sarker. Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions. SN Computer Science volume 2, Article number: 420 (2021)
[4]. Qiming Zhang, Haoyi Yu, Martina Barbiero, Baokai Wang and Min Gu. Artificial neural networks enabled by nanophotonics. Light: Science   Applications volume 8, Article number: 42 (2019)
[5]. Tang, Yingheng   Kojima, Keisuke   Koike-Akino, Toshiaki   Wang, Ye   Wu, Pengxiang   Tahersima, Mohammad H.   Jha, Devesh   Parsons, Kieran   Qi,. (2020). Generative Deep Learning Model for Inverse Design of Integrated Nanophotonic Devices. Laser   Photonics Review. 14. 10.1002/lpor.202000287.
[5]. Peter R. Wiecha and Otto L. Muskens. Deep Learning Meets Nanophotonics: A Generalized Accurate Predictor for Near Fields and Far Fields of Arbitrary 3D Nanostructures. Nano Letters 2020 20 (1), 329-338
[6]. Yingheng Tang, Keisuke Kojima, Toshiaki Koike-Akino, Ye Wang, Pengxiang Wu, Youye Xie, Mohammad H. Tahersima, Devesh K. Jha, Kieran Parsons and Minghao Qi. Generative Deep Learning Model for Inverse Design of Integrated Nanophotonic Devices. Laser and photonics reviews Volume14, Issue12 2020 2000287
[7]. Sensong An, Bowen Zheng, Hong Tang, Mikhail Y. Shalaginov, Li Zhou, Hang Li, Myungkoo Kang, Kathleen A. Richardson, Tian Gu, Juejun Hu, Clayton Fowler and Hualiang Zhang. Multifunctional Metasurface Design with a Generative Adversarial Network. Advanced optical materials. Volume9, Issue 5 2021 2001433.
[8]. Naseri, P., Goussetis, G., Fonseca, N.J.G. et al. Synthesis of multi-band reflective polarizing metasurfaces using a generative adversarial network. Sci Rep 12, 17006 (2022)
[9]. Maher G. M. Abdolrasol ,S. M. Suhail Hussain,Taha Selim Ustun ,Mahidur R. Sarker  ,Mahammad A. Hannan ,Ramizi Mohamed ,Jamal Abd Ali  ,Saad Mekhilef  and Abdalrhman Milad. Artificial Neural Networks Based Optimization Techniques: A Review. Electronics 2021, 10(21), 2689
[10]. Tahersima, M.H., Kojima, K., Koike-Akino, T. et al. Deep Neural Network Inverse Design of Integrated Photonic Power Splitters. Sci Rep 9, 1368 (2019).
[11]. Alec M. Hammond and Ryan M. Camacho, "Designing integrated photonic devices using artificial neural networks," Opt. Express 27, 29620-29638 (2019)
[12]. S. Chugh, S. Ghosh, A. Gulistan and B. M. A. Rahman, "Machine Learning Regression Approach to the Nanophotonic Waveguide Analyses," in Journal of Lightwave Technology, vol. 37, no. 24, pp. 6080-6089, 15 Dec.15, 2019, doi: 10.1109/JLT.2019.2946572.
[13]. Salmela, L., Tsipinakis, N., Foi, A. et al. Predicting ultrafast nonlinear dynamics in fibre optics with a recurrent neural network. Nat Mach Intell 3, 344–354 (2021).
[14]. 
[15]. Gulrajani, Ishaan   Ahmed, Faruk   Arjovsky, Martin   Dumoulin, Vincent   Courville, Aaron. Improved Training of Wasserstein GANs (2017).
[16]. Kingma, Diederik   Ba, Jimmy. Adam: A Method for Stochastic Optimization. International Conference on Learning Representations (2014).
[17]. Guo Z, Arandjelović O, Reid D, Lei Y. A Siamese Transformer Network for Zero-Shot Ancient Coin Classification. Journal of Imaging. 2023; 9(6):107. https://doi.org/10.3390/jimaging9060107
[18]. M. Raissi, P. Perdikaris, G.E. Karniadakis, Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations, Journal of Computational Physics, Volume 378, 2019, Pages 686-707, ISSN 0021-9991,
